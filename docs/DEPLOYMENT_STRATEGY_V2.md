# DictaMed v2.0 - Strat√©gie de D√©ploiement
## Architecture Multi-Entr√©es (Audio | Texte | Photos) + Agent OpenAI

---

## üéØ R√©sum√© de la Strat√©gie v2.0

### Changement Principal
```
AVANT (v1.0):
  Webhook ‚Üí 3 boucles parall√®les
  - Code JS (extraction)
  - Whisper API
  - Message Model
  ‚Üí Google Sheets (3 fois)

APR√àS (v2.0):
  Webhook Unique ‚Üí D√©terminer Type (Audio/Texte/Photo)

  IF AUDIO:
    Whisper API ‚Üí Agent OpenAI ‚Üí Google Sheets

  IF TEXTE:
    Agent OpenAI directement ‚Üí Google Sheets

  IF PHOTO:
    Vision API ‚Üí Agent OpenAI ‚Üí Google Sheets
```

### Avantages
- ‚úÖ 1 seul webhook pour tous les types
- ‚úÖ Logique conditionnelle automatique
- ‚úÖ Agent OpenAI central√© (moins de bruit API)
- ‚úÖ Scalable pour N utilisateurs √ó 3 types
- ‚úÖ Configuration Google Sheets simple
- ‚úÖ Co√ªts API optimis√©s

---

## üì¶ Fichiers Cr√©√©s

### Documentation
```
docs/N8N_CONDITIONAL_WORKFLOW_V2.md       ‚Üê Guide n8n (nouveau)
docs/FRONTEND_MODIFICATIONS_V2.md         ‚Üê Guide frontend (nouveau)
docs/DEPLOYMENT_STRATEGY_V2.md            ‚Üê Ce document
```

### Scripts
```
scripts/validate-payload-v2.js            ‚Üê Validation payload (nouveau)
scripts/audio-processor-v2.js             ‚Üê Traitement audio (nouveau)
```

### √Ä Modifier
```
js/components/data-sender.js              ‚Üê Refactor selon guide
js/core/config.js                         ‚Üê Ajouter INPUT_TYPES
[Composants UI]                           ‚Üê Adapter pour 3 types
```

---

## üîÑ Phases de D√©ploiement

### ‚úÖ PHASE 0: Pr√©paration (Avant tout)

**√âtape 0.1: Sauvegarder √âtat Actuel**
```bash
git add .
git commit -m "backup: before v2.0 migration"
git branch backup/v1.0
```

**√âtape 0.2: V√©rifier Cl√©s API**
```
‚úÖ OpenAI API Key (pour Whisper + GPT-4 + Vision)
‚úÖ Google Service Account (pour Sheets)
‚úÖ n8n acc√®s
```

**√âtape 0.3: Tester APIs Localement**
```javascript
// Test OpenAI avec node
const OpenAI = require('openai');
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Test Whisper (audio)
const whisperTest = await client.audio.transcriptions.create({
  file: fs.createReadStream('test.wav'),
  model: 'whisper-1',
  language: 'fr'
});
console.log("‚úÖ Whisper OK");

// Test GPT-4 (agent)
const gptTest = await client.chat.completions.create({
  model: 'gpt-4',
  messages: [{ role: 'user', content: 'Test' }]
});
console.log("‚úÖ GPT-4 OK");

// Test Vision
const visionTest = await client.chat.completions.create({
  model: 'gpt-4-vision',
  messages: [{
    role: 'user',
    content: [{
      type: 'image_url',
      image_url: { url: 'https://...' }
    }]
  }]
});
console.log("‚úÖ Vision OK");
```

---

### üìã PHASE 1: Configuration Google Sheets (15-20 min)

**√âtape 1.1: Cr√©er Sheet "DictaMed_Users"**
```
https://sheets.google.com/create
‚Üí Nommer: "DictaMed_Users"
‚Üí Colonnes (Ligne 1):
  A: uid          (Text)
  B: email        (Email)
  C: displayName  (Text)
  D: mode         (Text)
  E: prompt       (Long text)
  F: excel_file_id (Text)
  G: is_active    (Checkbox)
```

**√âtape 1.2: Ajouter Utilisateurs Test**
```
Ligne 2:
abc123test | student@med.fr | Dr. Test | normal | Tu es un cardiologue sp√©cialis√©... | [VIDE] | TRUE

Ligne 3:
xyz789test | doctor@med.fr | Dr. Autre | test | Tu es un g√©n√©raliste... | [VIDE] | TRUE
```

**√âtape 1.3: Obtenir ID Google Sheets**
```
URL: https://docs.google.com/spreadsheets/d/SHEET_ID/edit
Copier: SHEET_ID
Exemple: 1KxYz... (45 caract√®res)
```

**√âtape 1.4: Cr√©er Sheets R√©sultats (par utilisateur)**
```
Pour chaque utilisateur test:
1. Nouveau Sheet
2. Nommez: "DictaMed_Results_abc123test"
3. Colonnes:
   A: timestamp
   B: uid
   C: email
   D: displayName
   E: mode
   F: inputType       ‚Üê NOUVEAU
   G: patientInfo
   H: sympt√¥mes       ‚Üê Selon prompt
   I: diagnostic
   J: actions
   ... (personnalis√©)
4. Copier l'ID du sheet
5. Mettre cet ID dans "excel_file_id" du user
```

**√âtape 1.5: Partager avec Service Account**
```
1. Pour chaque sheet:
   Clic "Partager"
   ‚Üí Email: firebase-adminsdk-xxxxx@dictamed2025.iam.gserviceaccount.com
   ‚Üí Role: Editor
   ‚Üí Ne pas envoyer de notification

2. Copier l'ID dans config n8n
```

**Checklist Phase 1:**
- [ ] Sheet "DictaMed_Users" cr√©√©
- [ ] Colonnes correctes
- [ ] Utilisateurs test ajout√©s (au moins 2)
- [ ] Prompts remplis (au moins un template)
- [ ] Sheets r√©sultats cr√©√©s
- [ ] excel_file_id remplis dans DictaMed_Users
- [ ] Tous les sheets partag√©s avec service account

---

### üîß PHASE 2: Configuration n8n Workflow (45-60 min)

**√âtape 2.1: Ajouter Variables d'Environnement**
```
Settings ‚Üí Environment Variables

Ajouter:
OPENAI_API_KEY = sk-proj-...
DICTAMED_SHEETS_ID = [SHEET_ID_DictaMed_Users]
WHISPER_LANGUAGE = fr
AGENT_MODEL = gpt-4
VISION_MODEL = gpt-4-vision
```

**√âtape 2.2: Cr√©er Webhook Trigger**
```
Nouveau Workflow
Ajouter n≈ìud: Webhook

Configuration:
- Method: POST
- URL: /webhook/DictaMed
- Authentication: None (ou Bearer si pr√©f√©r√©)
- Response mode: When last node finishes
```

**√âtape 2.3: Ajouter Google Sheets Lookup**
```
N≈ìud 2: Google Sheets
Operation: Get a row
Authentication: Service Account
Spreadsheet: {{ $env.DICTAMED_SHEETS_ID }}
Sheet: Sheet1
Lookup column: uid
Lookup value: {{ $json.uid }}

Output: R√©cup√®re uid, email, displayName, prompt, excel_file_id
```

**√âtape 2.4: Ajouter IF Check**
```
N≈ìud 3: IF
Condition: Rows returned > 0
True: Continuer
False: HTTP Response 404
  Response: { "error": "User not found" }
```

**√âtape 2.5: Code JS - Contexte Global**
```javascript
N≈ìud 4: Code (JavaScript)

const userConfig = $nodeExecutionData[0].json;
const webhook = $nodeExecutionData[1].json;

return {
  uid: userConfig.uid,
  email: userConfig.email,
  displayName: userConfig.displayName,
  prompt: userConfig.prompt,
  excel_file_id: userConfig.excel_file_id,
  mode: webhook.mode,
  patientInfo: webhook.patientInfo,
  inputType: webhook.inputType,  // ‚Üê Cl√© de routage
  data: webhook.data,
  timestamp: webhook.timestamp
};
```

**√âtape 2.6: Ajouter Switch (Routage par Type)**
```
N≈ìud 5: Switch

Default: Error Response 400

Case 1:
  Condition: {{ $json.inputType === 'audio' }}
  ‚Üí Aller √† N≈ìud 5.1 (Whisper)

Case 2:
  Condition: {{ $json.inputType === 'text' }}
  ‚Üí Aller √† N≈ìud 5.4 (Direct Agent)

Case 3:
  Condition: {{ $json.inputType === 'photo' }}
  ‚Üí Aller √† N≈ìud 5.6 (Vision)
```

**√âtape 2.7: CHEMIN AUDIO (N≈ìuds 5.1-5.3)**

N≈ìud 5.1: Whisper API
```
HTTP Request
Method: POST
URL: https://api.openai.com/v1/audio/transcriptions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}

Body (form-data):
- file: Buffer.from($json.data.audioData, 'base64')
- model: whisper-1
- language: {{ $env.WHISPER_LANGUAGE }}
```

N≈ìud 5.2: Code JS (Pr√©parer pour Agent)
```javascript
const context = $nodeExecutionData[0].json;
const whisper = $nodeExecutionData[1].json;

return {
  ...context,
  rawContent: whisper.text,
  contentType: 'audio_transcription'
};
```

N≈ìud 5.3: Agent OpenAI
```
HTTP Request
Method: POST
URL: https://api.openai.com/v1/chat/completions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}
- Content-Type: application/json

Body (JSON):
{
  "model": "{{ $env.AGENT_MODEL }}",
  "temperature": 0.7,
  "max_tokens": 1500,
  "messages": [
    {
      "role": "system",
      "content": "{{ $json.prompt }}\n\nStructure la transcription audio en JSON valide."
    },
    {
      "role": "user",
      "content": "Transcription:\n\n{{ $json.rawContent }}"
    }
  ]
}
```

**√âtape 2.8: CHEMIN TEXTE (N≈ìuds 5.4-5.5)**

N≈ìud 5.4: Code JS (Pr√©parer pour Agent)
```javascript
const context = $nodeExecutionData[0].json;

return {
  ...context,
  rawContent: context.data.text,
  contentType: 'text_direct'
};
```

N≈ìud 5.5: Agent OpenAI (m√™me que 5.3 mais sans Whisper)
```
HTTP Request
[Identique √† 5.3, recevoir rawContent du texte]
```

**√âtape 2.9: CHEMIN PHOTO (N≈ìuds 5.6-5.8)**

N≈ìud 5.6: Vision API
```
HTTP Request
Method: POST
URL: https://api.openai.com/v1/chat/completions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}
- Content-Type: application/json

Body (JSON):
{
  "model": "{{ $env.VISION_MODEL }}",
  "max_tokens": 1500,
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Analyse cette image m√©dicale et extrais les observations."
        },
        {
          "type": "image_url",
          "image_url": {
            "url": "data:{{ $json.data.mimeType }};base64,{{ $json.data.photoData }}"
          }
        }
      ]
    }
  ]
}
```

N≈ìud 5.7: Code JS (Pr√©parer pour Agent)
```javascript
const context = $nodeExecutionData[0].json;
const vision = $nodeExecutionData[1].json;

return {
  ...context,
  rawContent: vision.choices[0].message.content,
  contentType: 'photo_analysis'
};
```

N≈ìud 5.8: Agent OpenAI
```
HTTP Request
[Identique √† 5.3/5.5, recevoir rawContent de Vision]
```

**√âtape 2.10: Consolidation (N≈ìud 6)**

```javascript
Code JS:

const agent = $nodeExecutionData[0].json;
const context = $nodeExecutionData[1].json;

let structured = {};
try {
  const response = agent.choices[0].message.content;
  structured = JSON.parse(response);
} catch (e) {
  structured = { raw: response };
}

return {
  timestamp: new Date().toISOString(),
  uid: context.uid,
  email: context.email,
  displayName: context.displayName,
  mode: context.mode,
  inputType: context.inputType,
  patientInfo: JSON.stringify(context.patientInfo),
  ...structured
};
```

**√âtape 2.11: Google Sheets Append (N≈ìud 7)**

```
Google Sheets
Operation: Append row
Spreadsheet: {{ $json.excel_file_id }}
Sheet: Sheet1

Columns:
- timestamp
- uid
- email
- displayName
- mode
- inputType
- patientInfo
- [toutes les colonnes structur√©es]

Values:
{{ $json.timestamp }}
{{ $json.uid }}
{{ $json.email }}
{{ $json.displayName }}
{{ $json.mode }}
{{ $json.inputType }}
{{ $json.patientInfo }}
... (etc)
```

**√âtape 2.12: Response (N≈ìud 8)**

```
HTTP Response

Status: 200
Body:
{
  "success": true,
  "inputType": "{{ $json.inputType }}",
  "timestamp": "{{ new Date().toISOString() }}"
}
```

**Checklist Phase 2:**
- [ ] Webhook cr√©√©: /webhook/DictaMed
- [ ] Variables d'environnement configur√©es
- [ ] N≈ìud 1-4: Core (Webhook, Lookup, IF, Context)
- [ ] N≈ìud 5: Switch pour 3 types
- [ ] N≈ìud 5.1-5.3: Audio path (Whisper ‚Üí Agent)
- [ ] N≈ìud 5.4-5.5: Text path (Direct ‚Üí Agent)
- [ ] N≈ìud 5.6-5.8: Photo path (Vision ‚Üí Agent)
- [ ] N≈ìud 6: Consolidation
- [ ] N≈ìud 7: Google Sheets Append
- [ ] N≈ìud 8: Response
- [ ] Workflow d√©ploy√© (Publish/Save)

---

### üíª PHASE 3: Modifications Frontend (30-45 min)

**√âtape 3.1: Mettre √† Jour config.js**
```javascript
// js/core/config.js

const APP_CONFIG = {
  // ... configs existantes ...

  INPUT_TYPES: {
    AUDIO: 'audio',
    TEXT: 'text',
    PHOTO: 'photo'
  },

  AUDIO_CONFIG: {
    maxDuration: 300,
    maxSizeBytes: 25 * 1024 * 1024,
    compression: { enabled: true, sampleRate: 16000 }
  },

  TEXT_CONFIG: {
    minLength: 5,
    maxLength: 50000
  },

  PHOTO_CONFIG: {
    maxSizeBytes: 20 * 1024 * 1024,
    allowedMimes: ['image/jpeg', 'image/png', 'image/webp']
  },

  WEBHOOK_ENDPOINTS: {
    normal: 'https://n8n.example.com/webhook/DictaMed',
    test: 'https://n8n.example.com/webhook/DictaMed-Test',
    dmi: 'https://n8n.example.com/webhook/DictaMed'
  }
};
```

**√âtape 3.2: Refactoriser data-sender.js**
```
Suivre: docs/FRONTEND_MODIFICATIONS_V2.md

Points cl√©s:
- Importer validate-payload-v2.js
- Importer audio-processor-v2.js
- Cr√©er classe DataSender
- Impl√©menter determineInputType()
- Impl√©menter processAudioData()
- Impl√©menter processTextData()
- Impl√©menter processPhotoData()
- Adapter buildPayload() pour input wrapper
```

**√âtape 3.3: Adapter Composants UI**

Audio Recorder:
```javascript
// R√©cup√©rer audioBlob avant conversion base64
const recordingData = {
  audioBlob: blob,
  duration: seconds,
  format: 'webm'
};
await sendDataToWebhook(user, recordingData, mode);
```

Text Component:
```javascript
const recordingData = {
  text: textInput.value,
  format: 'text/plain'
};
await sendDataToWebhook(user, recordingData, mode);
```

Photo Upload:
```javascript
const recordingData = {
  photoBlob: file,
  mimeType: file.type,
  description: descriptionInput.value
};
await sendDataToWebhook(user, recordingData, mode);
```

**√âtape 3.4: Tester Localement**

En console (ou script de test):
```javascript
// Test Audio
const audioBlob = new Blob(['...'], { type: 'audio/webm' });
await sendDataToWebhook(user, { audioBlob, duration: 30 }, 'test');
console.log("‚úÖ Audio test OK");

// Test Texte
await sendDataToWebhook(user, { text: "Patient 45 ans..." }, 'test');
console.log("‚úÖ Texte test OK");

// Test Photo
const photoBlob = new Blob(['...'], { type: 'image/jpeg' });
await sendDataToWebhook(user, { photoBlob, mimeType: 'image/jpeg' }, 'test');
console.log("‚úÖ Photo test OK");
```

**Checklist Phase 3:**
- [ ] config.js mis √† jour (INPUT_TYPES, configs)
- [ ] data-sender.js refactoris√©
- [ ] validate-payload-v2.js import√©
- [ ] audio-processor-v2.js import√©
- [ ] Composant audio adapt√©
- [ ] Composant texte adapt√©/cr√©√©
- [ ] Composant photo adapt√©/cr√©√©
- [ ] Tests locaux pass√©s (audio, texte, photo)
- [ ] Console sans erreurs
- [ ] Validations affich√©es en debug

---

### üß™ PHASE 4: Tests Int√©gration (20-30 min)

**√âtape 4.1: Test Audio Complet**
```
1. Frontend:
   - Ouvrir Mode Normal/Test
   - Enregistrer 10-15 secondes audio
   - Cliquer "Envoyer"
   - Attendre 30-60 secondes

2. V√©rifier n8n:
   - Webhook re√ßu
   - Utilisateur trouv√©
   - Whisper transcription OK
   - Agent structuration OK
   - Google Sheets append OK

3. V√©rifier Google Sheets:
   - Nouvelle ligne ajout√©e
   - inputType = "audio"
   - Donn√©es structur√©es pr√©sentes
```

**√âtape 4.2: Test Texte Complet**
```
1. Frontend:
   - Mode Texte
   - Entrer texte m√©dical (10+ mots)
   - Cliquer "Envoyer"
   - Attendre 15-30 secondes

2. V√©rifier n8n:
   - Webhook re√ßu
   - Utilisateur trouv√©
   - Whisper SKIPPED (texte direct)
   - Agent structuration OK
   - Google Sheets append OK

3. V√©rifier Google Sheets:
   - Nouvelle ligne ajout√©e
   - inputType = "text"
   - Donn√©es structur√©es pr√©sentes
```

**√âtape 4.3: Test Photo Complet**
```
1. Frontend:
   - Mode Photo
   - Uploader image JPEG/PNG
   - Entrer description
   - Cliquer "Envoyer"
   - Attendre 15-30 secondes

2. V√©rifier n8n:
   - Webhook re√ßu
   - Utilisateur trouv√©
   - Vision API analyse OK
   - Agent structuration OK
   - Google Sheets append OK

3. V√©rifier Google Sheets:
   - Nouvelle ligne ajout√©e
   - inputType = "photo"
   - Observations pr√©sentes
```

**√âtape 4.4: Test Erreurs**

404 - Utilisateur absent:
```
Payload: uid = "user-not-in-sheets"
R√©sultat: 404 "User not found" dans n8n
```

400 - Whisper API failure:
```
Payload: audioData invalide (non-base64)
R√©sultat: 400 "Audio transcription failed"
```

400 - Agent failure:
```
Payload: prompt invalide ou tr√®s bizarre
R√©sultat: 500 "Data structuring failed" avec retry
```

**Checklist Phase 4:**
- [ ] Test audio: ‚úÖ Texte envoy√©, Google Sheets OK
- [ ] Test texte: ‚úÖ Donn√©es re√ßues, Google Sheets OK
- [ ] Test photo: ‚úÖ Observations, Google Sheets OK
- [ ] Erreur 404: ‚úÖ User not found
- [ ] Erreur 400: ‚úÖ G√©r√©e correctement
- [ ] Pas de crashes frontend
- [ ] Pas de timeouts (< 60s)
- [ ] Notifications utilisateur correctes

---

### üöÄ PHASE 5: Migration Utilisateurs (5-10 min)

**√âtape 5.1: Ex√©cuter Script Migration**
```bash
cd c:\DictaMed\developerMode
node scripts/migrate-users-to-sheets.js

# R√©pondre:
# ? ID Google Sheet "DictaMed_Users": 1KxYz...
# ‚úÖ Exportant utilisateurs Firestore...
# ‚úÖ 25 utilisateurs export√©s
# ‚ö†Ô∏è  Remplir manuellement prompts + excel_file_id
```

**√âtape 5.2: Compl√©ter Manuellement**
```
Pour chaque utilisateur:
1. Ouvrir "DictaMed_Users" sheet
2. Remplir colonne "prompt" (template ou sp√©cialis√©)
3. Cr√©er Google Sheet r√©sultats
4. Remplir colonne "excel_file_id"
5. Marquer "is_active" = TRUE
```

**√âtape 5.3: V√©rifier Migration**
```javascript
// Test dans n8n
const testUser = {
  uid: 'user_from_migration',
  email: 'real@user.email'
};
// Devrait trouver user dans Google Sheets
// Devrait avoir prompt + excel_file_id
```

**Checklist Phase 5:**
- [ ] Script ex√©cut√© sans erreurs
- [ ] Utilisateurs dans Google Sheets
- [ ] Prompts remplis
- [ ] excel_file_id remplis
- [ ] is_active = TRUE pour test users
- [ ] Test lookup utilisateur r√©el OK

---

### üìä PHASE 6: Monitoring & D√©ploiement (10-15 min)

**√âtape 6.1: Configurer Monitoring n8n**

```
n8n Settings ‚Üí Notifications

Email Alert:
- On workflow error
- On workflow timeout
- Destinataire: admin@med.fr
```

**√âtape 6.2: Cr√©er Dashboard Monitoring**

```javascript
// Cr√©er script logs parser (optionnel)
scripts/monitor-n8n-logs.js

// Surveiller:
// - Lookup failures (404 users)
// - Whisper errors (audio issues)
// - Vision errors (photo issues)
// - Agent errors (structuring)
// - Google Sheets errors (append failures)
```

**√âtape 6.3: D√©ployer Code Frontend**

```bash
git add .
git commit -m "feat: migrate to v2.0 conditional workflow with multi-input support"
git push origin main

# Si utilisant Firebase Hosting:
firebase deploy
```

**√âtape 6.4: Configurer Firestore Rules (si n√©cessaire)**

```
firebase deploy --only firestore:rules
```

**√âtape 6.5: V√©rifier Production**

```bash
# Tester endpoints en production
curl -X POST https://dictamed.com/webhook/test \
  -H "Content-Type: application/json" \
  -d '{"uid":"test","inputType":"text","data":{"text":"Test"}}'
```

**Checklist Phase 6:**
- [ ] Monitoring n8n configur√©
- [ ] Alertes email actives
- [ ] Code commit√© et push√©
- [ ] Firebase deployed
- [ ] Firestore rules deployed
- [ ] Endpoints v√©rifi√© en production
- [ ] Backups configur√©s

---

## ‚è±Ô∏è Timeline Estim√©e

| Phase | Dur√©e | D√©pendances |
|-------|-------|------------|
| 0. Pr√©paration | 5 min | - |
| 1. Google Sheets | 20 min | Acc√®s Google |
| 2. n8n Workflow | 60 min | Cl√©s API, n8n |
| 3. Frontend | 45 min | Phase 2 |
| 4. Tests | 30 min | Phase 1-3 |
| 5. Migration Users | 10 min | Phase 1-4 |
| 6. Monitoring | 15 min | Phase 5 |
| **TOTAL** | **3-3.5 h** | - |

---

## üìö Documents de R√©f√©rence

| Document | Utilisation |
|----------|------------|
| [N8N_CONDITIONAL_WORKFLOW_V2.md](N8N_CONDITIONAL_WORKFLOW_V2.md) | Guide d√©taill√© n8n |
| [FRONTEND_MODIFICATIONS_V2.md](FRONTEND_MODIFICATIONS_V2.md) | Code frontend √† modifier |
| [validate-payload-v2.js](../scripts/validate-payload-v2.js) | Validation payload |
| [audio-processor-v2.js](../scripts/audio-processor-v2.js) | Traitement audio |

---

## üÜò Troubleshooting Rapide

### Erreur: "inputType invalide"
**‚Üí** Frontend n'envoie pas inputType dans payload
**‚Üí** Solution: V√©rifier determineInputType() dans data-sender.js

### Erreur: "Whisper API failed"
**‚Üí** Format audio invalide ou API down
**‚Üí** Solution: Tester cl√© API, v√©rifier format audio (webm, mp3, wav)

### Erreur: "User not found"
**‚Üí** uid absent de Google Sheets "DictaMed_Users"
**‚Üí** Solution: V√©rifier utilisateur existe, v√©rifier colonne uid exacte

### Erreur: "Agent structuration failed"
**‚Üí** Prompt invalide ou response non-JSON
**‚Üí** Solution: V√©rifier prompt dans Google Sheets, adapter parser robuste

### Google Sheets append √©choue
**‚Üí** Permissions manquantes ou sheet_id invalide
**‚Üí** Solution: V√©rifier partage service account, v√©rifier ID sheet

---

## üìã Checklist Finale

### Code
- [ ] config.js INPUT_TYPES ajout√©s
- [ ] data-sender.js refactoris√©
- [ ] validate-payload-v2.js int√©gr√©
- [ ] audio-processor-v2.js int√©gr√©
- [ ] Composants audio/texte/photo adapt√©s
- [ ] Tests locaux pass√©s

### Google Sheets
- [ ] "DictaMed_Users" cr√©√© avec colonnes
- [ ] Utilisateurs test ajout√©s
- [ ] Prompts remplis
- [ ] Sheets r√©sultats cr√©√©s
- [ ] excel_file_id remplis
- [ ] Service account partag√©

### n8n
- [ ] Variables d'environnement configur√©es
- [ ] Webhook /webhook/DictaMed cr√©√©
- [ ] N≈ìuds 1-8 configur√©s
- [ ] Switch routing (3 chemins) OK
- [ ] Tests n≈ìud par n≈ìud OK
- [ ] Workflow d√©ploy√©

### Tests
- [ ] Test audio complet: ‚úÖ
- [ ] Test texte complet: ‚úÖ
- [ ] Test photo complet: ‚úÖ
- [ ] Test erreur 404: ‚úÖ
- [ ] Test erreur API: ‚úÖ
- [ ] Test end-to-end: ‚úÖ

### Production
- [ ] Code commit√© et push√©
- [ ] Monitoring configur√©
- [ ] Alertes actives
- [ ] Backups en place
- [ ] Utilisateurs r√©els migr√©s
- [ ] Production v√©rifi√©e

---

## üéâ Fin du D√©ploiement

Une fois tous les checklist pass√©s:

```bash
# Commit final
git add .
git commit -m "feat: v2.0 deployment complete - multi-input with conditional routing"
git tag v2.0
git push --tags
```

**Statut:** ‚úÖ Production Ready
**Version:** 2.0.0
**Derni√®re mise √† jour:** 2025-01-15

---

## üìû Support

Pour des questions:
- Consultez les 3 documents principaux
- V√©rifiez les logs n8n
- Testez avec curl les endpoints
- Contactez: akio963@gmail.com
