# DictaMed - n8n Workflow Conditionnel v2.0
## Architecture Multi-Entr√©es (Audio | Texte | Photos) avec Agent OpenAI

---

## üìã Vue d'ensemble

Cette nouvelle architecture utilise **1 seul webhook** pour traiter 3 types d'entr√©es diff√©rentes :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    WEBHOOK UNIQUE (DictaMed)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         1. R√©cup√©rer Prompt depuis Google Sheets                 ‚îÇ
‚îÇ         2. D√©terminer Type d'Entr√©e (Audio/Texte/Photo)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº                     ‚ñº          ‚ñº
              ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó          ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
              ‚ïë  AUDIO  ‚ïë          ‚ïë  TEXTE  ‚ïë    ‚ïë  PHOTO  ‚ïë
              ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
                    ‚ñº                     ‚ñº          ‚ñº
            [Whisper API]      [Directement]  [Vision API]
                    ‚ñº                     ‚ñº          ‚ñº
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚ñº
                    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
                    ‚ïë  Agent OpenAI      ‚ïë
                    ‚ïë  (Structuration)   ‚ïë
                    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
                               ‚ñº
                    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
                    ‚ïë  Google Sheets     ‚ïë
                    ‚ïë  Append Row        ‚ïë
                    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
                               ‚ñº
                    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
                    ‚ïë  Response 200 OK   ‚ïë
                    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

### Avantages
- ‚úÖ 1 seul webhook pour tous les types d'entr√©es
- ‚úÖ Logique conditionnelle automatique par type
- ‚úÖ Prompts personnalis√©s par utilisateur (Google Sheets)
- ‚úÖ Scalable √† 500+ utilisateurs
- ‚úÖ Utilise agent OpenAI existant

---

## üèóÔ∏è Architecture D√©taill√©e

### Payload du Frontend

```json
{
  "uid": "abc123xyz",
  "email": "student@med.fr",
  "displayName": "Dr. Martin",
  "mode": "normal",
  "timestamp": "2025-01-15T10:30:00Z",
  "patientInfo": {
    "numeroDossier": "D123456",
    "nomPatient": "Jean Dupont"
  },
  "inputType": "audio",           // ‚Üê NOUVEAU: audio | text | photo
  "data": {
    // Si inputType = "audio"
    "audioData": "base64_encoded_audio...",
    "duration": 45,
    "format": "webm"

    // OU si inputType = "text"
    "text": "Le patient se plaint de...",
    "format": "text/plain"

    // OU si inputType = "photo"
    "photoData": "base64_image...",
    "mimeType": "image/jpeg",
    "description": "Photo de la radiographie"
  },
  "metadata": { }
}
```

---

## üîß Architecture n8n Pas-√†-Pas

### N≈íUD 1: Webhook Trigger

```
Type: Webhook
Method: POST
URL: /webhook/DictaMed
Authentication: None (ou token)
Response mode: When last node finishes
```

### N≈íUD 2: Google Sheets Lookup (R√©cup√©rer Prompt + Config)

```
Type: Google Sheets
Operation: Get a row
Authentication: Service Account
Spreadsheet: DictaMed_Users
Sheet: Sheet1
Lookup column: uid
Lookup value: {{ $json.uid }}
```

**Output r√©cup√©r√©:**
```json
{
  "uid": "abc123",
  "email": "student@med.fr",
  "prompt": "Tu es un assistant m√©dical sp√©cialis√© en cardiologie...",
  "excel_file_id": "sheet_id_utilisateur",
  "is_active": true
}
```

### N≈íUD 3: IF - V√©rifier Utilisateur Trouv√©

```
Type: IF
Condition: Rows returned > 0
True: Continuer
False: Envoyer erreur 404
```

### N≈íUD 4: Code JS - Pr√©parer le Contexte + D√©terminer Type

```javascript
Type: Code
Language: JavaScript
```

**Code:**
```javascript
// R√©cup√©rer les donn√©es
const userConfig = $nodeExecutionData[0].json;  // Google Sheets lookup
const webhookPayload = $nodeExecutionData[0].json;  // Webhook original

// Pr√©parer le contexte global
return {
  uid: userConfig.uid,
  email: userConfig.email,
  displayName: userConfig.displayName,
  mode: webhookPayload.mode,
  prompt: userConfig.prompt,
  excel_file_id: userConfig.excel_file_id,
  patientInfo: webhookPayload.patientInfo,
  inputType: webhookPayload.inputType,  // ‚Üê Cl√© pour le routage
  data: webhookPayload.data,
  timestamp: webhookPayload.timestamp
};
```

**Output:**
```json
{
  "uid": "abc123",
  "email": "student@med.fr",
  "prompt": "Tu es un assistant...",
  "excel_file_id": "sheet_id",
  "inputType": "audio",  // ‚Üê Utilis√© pour le routage
  "data": { ... },
  "patientInfo": { ... }
}
```

### N≈íUD 5: Switch (Routage par Type d'Entr√©e)

```
Type: Switch
Default: Error

Case 1: inputType === "audio"
Case 2: inputType === "text"
Case 3: inputType === "photo"
```

---

## üéµ CHEMIN 1: TRAITEMENT AUDIO

### N≈íUD 5.1: Whisper API (Transcription)

```
Type: HTTP Request
Method: POST
URL: https://api.openai.com/v1/audio/transcriptions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}

Body (form-data):
- file: [Binary Audio File]
- model: whisper-1
- language: fr
```

**Expression pour le fichier audio:**
```javascript
// Convertir base64 en buffer
Buffer.from($json.data.audioData, 'base64')
```

**Output:**
```json
{
  "text": "Le patient se plaint de douleurs thoraciques depuis 3 jours...",
  "language": "fr"
}
```

### N≈íUD 5.2: Code JS - Pr√©parer pour Agent (Audio Path)

```javascript
Type: Code
Language: JavaScript
```

**Code:**
```javascript
const context = $nodeExecutionData[0].json;  // Contexte global
const transcription = $nodeExecutionData[1].json;  // Whisper output

return {
  ...context,
  rawContent: transcription.text,
  contentType: "transcription_audio",
  contentLength: transcription.text.length,
  originalDuration: context.data.duration
};
```

### N≈íUD 5.3: HTTP Request ‚Üí OpenAI Agent (Structuration)

```
Type: HTTP Request
Method: POST
URL: https://api.openai.com/v1/chat/completions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}
- Content-Type: application/json
```

**Body (JSON):**
```json
{
  "model": "gpt-4",
  "temperature": 0.7,
  "max_tokens": 1500,
  "messages": [
    {
      "role": "system",
      "content": "{{ $json.prompt }}\n\nStructure les donn√©es en JSON valide avec les champs appropri√©s."
    },
    {
      "role": "user",
      "content": "Voici la transcription m√©dicale √† structurer:\n\n{{ $json.rawContent }}"
    }
  ]
}
```

**Output Parsing:**
```javascript
// Extraire la r√©ponse
const response = $nodeExecutionData[2].json;
const content = response.choices[0].message.content;

// Parser JSON si possible
let structured = {};
try {
  structured = JSON.parse(content);
} catch (e) {
  structured = { raw_response: content };
}

return {
  structured: structured,
  model: "gpt-4",
  tokens_used: response.usage.total_tokens
};
```

---

## üìù CHEMIN 2: TRAITEMENT TEXTE

### N≈íUD 5.4: Code JS - Pr√©parer pour Agent (Texte Path)

```javascript
Type: Code
Language: JavaScript
```

**Code:**
```javascript
const context = $nodeExecutionData[0].json;  // Contexte global

return {
  ...context,
  rawContent: context.data.text,
  contentType: "texte_direct",
  contentLength: context.data.text.length
};
```

### N≈íUD 5.5: HTTP Request ‚Üí OpenAI Agent (Structuration)

```
Type: HTTP Request
Method: POST
URL: https://api.openai.com/v1/chat/completions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}
- Content-Type: application/json
```

**Body (JSON):**
```json
{
  "model": "gpt-4",
  "temperature": 0.7,
  "max_tokens": 1500,
  "messages": [
    {
      "role": "system",
      "content": "{{ $json.prompt }}\n\nStructure le texte m√©dical fourni en JSON valide."
    },
    {
      "role": "user",
      "content": "Texte m√©dical √† structurer:\n\n{{ $json.rawContent }}"
    }
  ]
}
```

**Output Parsing:** (Identique au chemin audio)

---

## üì∑ CHEMIN 3: TRAITEMENT PHOTOS

### N≈íUD 5.6: Vision API (Analyse d'Image)

```
Type: HTTP Request
Method: POST
URL: https://api.openai.com/v1/chat/completions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}
- Content-Type: application/json
```

**Body (JSON):**
```json
{
  "model": "gpt-4-vision",
  "max_tokens": 1500,
  "messages": [
    {
      "role": "system",
      "content": "Tu es un assistant d'analyse d'imagerie m√©dicale. Analyse l'image fournie et extrais les informations pertinentes."
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "{{ $json.prompt }}\n\nAnalyse cette image m√©dicale:"
        },
        {
          "type": "image_url",
          "image_url": {
            "url": "data:{{ $json.data.mimeType }};base64,{{ $json.data.photoData }}"
          }
        }
      ]
    }
  ]
}
```

**Output:**
```json
{
  "content": "Description structur√©e de l'image...",
  "observations": [...]
}
```

### N≈íUD 5.7: Code JS - Pr√©parer pour Agent (Photo Path)

```javascript
Type: Code
Language: JavaScript
```

**Code:**
```javascript
const context = $nodeExecutionData[0].json;
const visionResponse = $nodeExecutionData[1].json;

return {
  ...context,
  rawContent: visionResponse.choices[0].message.content,
  contentType: "analyse_photo",
  photoDescription: context.data.description,
  imageMimeType: context.data.mimeType
};
```

### N≈íUD 5.8: HTTP Request ‚Üí OpenAI Agent (Structuration)

```
Type: HTTP Request
Method: POST
URL: https://api.openai.com/v1/chat/completions

Headers:
- Authorization: Bearer {{ $env.OPENAI_API_KEY }}
- Content-Type: application/json
```

**Body (JSON):**
```json
{
  "model": "gpt-4",
  "temperature": 0.7,
  "max_tokens": 1500,
  "messages": [
    {
      "role": "system",
      "content": "{{ $json.prompt }}\n\nStructure les donn√©es extraites de l'analyse d'imagerie en JSON valide."
    },
    {
      "role": "user",
      "content": "Analyse d'image:\n\n{{ $json.rawContent }}"
    }
  ]
}
```

---

## üîÄ N≈íUD 6: Consolidation (Apr√®s les 3 Chemins)

### Code JS - Pr√©parer pour Google Sheets

```javascript
Type: Code
Language: JavaScript
```

**Code:**
```javascript
// Les 3 chemins convergent ici
// $nodeExecutionData contient le r√©sultat du chemin pris

const result = $nodeExecutionData[0].json;
const context = $nodeExecutionData[1].json;

// Parser la r√©ponse de l'agent
let structured = {};
try {
  // La r√©ponse est dans choices[0].message.content
  const responseText = result.choices[0].message.content;
  structured = JSON.parse(responseText);
} catch (e) {
  structured = { raw_response: result.choices[0].message.content };
}

// Formater pour Google Sheets
return {
  timestamp: new Date().toISOString(),
  uid: context.uid,
  email: context.email,
  displayName: context.displayName,
  mode: context.mode,
  inputType: context.inputType,
  patientInfo: JSON.stringify(context.patientInfo),
  ...structured,  // D√©plie les champs structur√©s
  tokens_used: result.usage.total_tokens
};
```

**Output Consolid√©:**
```json
{
  "timestamp": "2025-01-15T10:30:00Z",
  "uid": "abc123",
  "email": "student@med.fr",
  "displayName": "Dr. Martin",
  "mode": "normal",
  "inputType": "audio",
  "patientInfo": "{\"numeroDossier\": \"D123\", ...}",
  "sympt√¥mes": "Douleurs thoraciques, dyspn√©e",
  "diagnostic": "Suspicion d'infarctus",
  "actions": ["ECG", "Troponine"],
  "tokens_used": 542
}
```

---

## üìä N≈íUD 7: Google Sheets Append

```
Type: Google Sheets
Operation: Append row
Authentication: Service Account
Spreadsheet: {{ $json.excel_file_id }}
Sheet: Sheet1
Columns to insert:
  - timestamp
  - uid
  - email
  - displayName
  - mode
  - inputType
  - patientInfo
  - [toutes les colonnes structur√©es par l'agent]
```

**Values:**
```
{{ $json.timestamp }}
{{ $json.uid }}
{{ $json.email }}
{{ $json.displayName }}
{{ $json.mode }}
{{ $json.inputType }}
{{ $json.patientInfo }}
{{ $json.sympt√¥mes }}
{{ $json.diagnostic }}
{{ $json.actions }}
... (etc)
```

---

## ‚úÖ N≈íUD 8: Response (Webhook Response)

```
Type: HTTP Response
Response: 200 OK
```

**Body:**
```json
{
  "success": true,
  "message": "Data processed successfully",
  "inputType": "{{ $json.inputType }}",
  "rowAppended": true,
  "timestamp": "{{ new Date().toISOString() }}"
}
```

---

## üìå Configuration Google Sheets

### Sheet "DictaMed_Users"

**Colonnes:**
```
A: uid              (Text)
B: email            (Email)
C: displayName      (Text)
D: mode             (Text)
E: prompt           (Long text - syst√®me ou sp√©cialis√©)
F: excel_file_id    (Text - ID du sheet r√©sultats)
G: is_active        (Checkbox)
```

**Exemple Row:**
```
abc123 | student@med.fr | Dr. Martin | normal | Tu es un cardiologue... | 1KxYz... | ‚úì
```

### Sheet R√©sultats (Personnalis√© par Utilisateur)

**Colonnes de Base:**
```
A: timestamp
B: uid
C: email
D: displayName
E: mode
F: inputType      ‚Üê NOUVEAU: audio | text | photo
G: patientInfo
```

**Colonnes Dynamiques (selon prompt):**
```
H: sympt√¥mes
I: diagnostic
J: actions
K: diff√©rentiels
L: examens_demand√©s
... (personnalis√©es par prompt de l'utilisateur)
```

---

## üîê Variables d'Environnement n8n

```env
# APIs
OPENAI_API_KEY=sk-proj-...           # Pour Whisper, GPT-4, Vision
GOOGLE_SHEETS_SPREADSHEET_ID=...     # ID du sheet "DictaMed_Users"

# Configuration (optionnel)
WHISPER_LANGUAGE=fr
AGENT_MODEL=gpt-4
AGENT_TEMPERATURE=0.7
VISION_MODEL=gpt-4-vision
```

---

## üìã Payload Frontend Exemple

### Exemple 1: Audio

```json
{
  "uid": "abc123xyz",
  "email": "student@med.fr",
  "displayName": "Dr. Martin",
  "mode": "normal",
  "timestamp": "2025-01-15T10:30:00Z",
  "patientInfo": {
    "numeroDossier": "D123456",
    "nomPatient": "Jean Dupont"
  },
  "inputType": "audio",
  "data": {
    "audioData": "SUQzBAAAI1NDVEgA...",
    "duration": 45,
    "format": "webm"
  },
  "metadata": {}
}
```

### Exemple 2: Texte

```json
{
  "uid": "abc123xyz",
  "email": "student@med.fr",
  "displayName": "Dr. Martin",
  "mode": "normal",
  "timestamp": "2025-01-15T10:30:00Z",
  "patientInfo": {
    "numeroDossier": "D123456",
    "nomPatient": "Jean Dupont"
  },
  "inputType": "text",
  "data": {
    "text": "Patient de 45 ans se pr√©sentant avec des douleurs thoraciques depuis 3 jours...",
    "format": "text/plain"
  },
  "metadata": {}
}
```

### Exemple 3: Photo

```json
{
  "uid": "abc123xyz",
  "email": "student@med.fr",
  "displayName": "Dr. Martin",
  "mode": "normal",
  "timestamp": "2025-01-15T10:30:00Z",
  "patientInfo": {
    "numeroDossier": "D123456",
    "nomPatient": "Jean Dupont"
  },
  "inputType": "photo",
  "data": {
    "photoData": "/9j/4AAQSkZJRgABA...",
    "mimeType": "image/jpeg",
    "description": "Radiographie thoracique de face"
  },
  "metadata": {}
}
```

---

## üß™ Tests √âtape-par-√âtape

### Test 1: Webhook + Lookup (Tous les Chemins)

**Payload:**
```json
{
  "uid": "test-user-123",
  "email": "test@example.com",
  "displayName": "Test User",
  "mode": "test",
  "inputType": "text",
  "data": {"text": "Test de texte"},
  "patientInfo": {},
  "timestamp": "2025-01-15T10:00:00Z"
}
```

**R√©sultat attendu:**
```
‚úÖ Utilisateur trouv√© dans Google Sheets
‚úÖ Prompt r√©cup√©r√©
‚úÖ excel_file_id r√©cup√©r√©
```

### Test 2: Chemin Audio Complet

**Payload avec audio real:**
```json
{
  "uid": "test-user-123",
  "email": "test@example.com",
  "displayName": "Test User",
  "inputType": "audio",
  "data": {
    "audioData": "[base64_audio]",
    "duration": 30,
    "format": "webm"
  },
  ...
}
```

**R√©sultats attendus:**
```
‚úÖ Whisper API transcription r√©ussie
‚úÖ Agent OpenAI structure les donn√©es
‚úÖ Google Sheets append r√©ussit
```

### Test 3: Chemin Texte Complet

**Payload:**
```json
{
  "uid": "test-user-123",
  "inputType": "text",
  "data": {"text": "Patient avec sympt√¥mes..."},
  ...
}
```

**R√©sultats attendus:**
```
‚úÖ Skipped Whisper (input texte)
‚úÖ Agent OpenAI re√ßoit le texte directement
‚úÖ Google Sheets append r√©ussit
```

### Test 4: Chemin Photo Complet

**Payload:**
```json
{
  "uid": "test-user-123",
  "inputType": "photo",
  "data": {
    "photoData": "[base64_image]",
    "mimeType": "image/jpeg",
    "description": "Radiographie"
  },
  ...
}
```

**R√©sultats attendus:**
```
‚úÖ Vision API analyse l'image
‚úÖ Agent OpenAI structure les observations
‚úÖ Google Sheets append r√©ussit
```

---

## üõ†Ô∏è Gestion des Erreurs

### Erreur Handler - Whisper API Failure

```
Condition: inputType = "audio" AND Whisper error
Response: 400 - "Audio transcription failed"
Fallback: Envoyer email admin
```

### Erreur Handler - Vision API Failure

```
Condition: inputType = "photo" AND Vision error
Response: 400 - "Image analysis failed"
Fallback: Envoyer email admin
```

### Erreur Handler - Agent Failure (Tous les Chemins)

```
Condition: Agent OpenAI error (timeout, invalid response, etc)
Response: 500 - "Data structuring failed"
Fallback: Envoyer email admin + Log d√©taill√©
```

### Erreur Handler - Google Sheets Append

```
Condition: Append fails
Response: 500 - "Failed to save data"
Fallback: Retry 3x avec backoff exponentiel
```

---

## üìà Performance & Optimisations

### Timeouts

```
Whisper API:     120 secondes (audio max 25MB)
Vision API:      60 secondes (image max 20MB)
Agent OpenAI:    60 secondes (processing)
Google Sheets:   30 secondes (append)
Total Workflow:  300 secondes (5 minutes max)
```

### Rate Limits

```
OpenAI (Whisper):      50 req/min
OpenAI (GPT-4):        3500 req/min (selon plan)
OpenAI (Vision):       3500 req/min (selon plan)
Google Sheets API:     300 req/min
```

### Optimisations Recommand√©es

```javascript
// 1. Caching du Lookup Google Sheets (5 min)
// 2. Compression audio avant Whisper (max 5MB base64)
// 3. Redimensionner images (max 2MB base64)
// 4. Batching des √©critures Google Sheets (grouper 10 req)
```

---

## üîÑ Frontend - Modifier data-sender.js

```javascript
// Ajouter d√©tection du type d'entr√©e
function determineInputType(data) {
  if (data.audioData) return "audio";
  if (data.text) return "text";
  if (data.photoData) return "photo";
  return "unknown";
}

// Modifier le payload
const payload = {
  uid: user.uid,
  email: user.email,
  displayName: user.displayName,
  mode: currentMode,
  timestamp: new Date().toISOString(),
  patientInfo: getPatientInfo(),
  inputType: determineInputType(recordingData),  // ‚Üê NOUVEAU
  data: recordingData,  // ‚Üê Wrapper pour audio/texte/photo
  metadata: {}
};
```

---

## üìö Script de Validation

### Script JS - Valider Payload Frontend

```javascript
// Cr√©er: scripts/validate-payload.js

const fs = require('fs');

function validatePayload(payload) {
  const errors = [];

  // Champs requis
  if (!payload.uid) errors.push("uid manquant");
  if (!payload.email) errors.push("email manquant");
  if (!payload.inputType) errors.push("inputType manquant");

  // Validation par type
  if (payload.inputType === "audio") {
    if (!payload.data.audioData) errors.push("audioData manquant");
    if (!payload.data.duration) errors.push("duration manquant");
  } else if (payload.inputType === "text") {
    if (!payload.data.text) errors.push("text manquant");
  } else if (payload.inputType === "photo") {
    if (!payload.data.photoData) errors.push("photoData manquant");
    if (!payload.data.mimeType) errors.push("mimeType manquant");
  } else {
    errors.push(`inputType invalide: ${payload.inputType}`);
  }

  return {
    valid: errors.length === 0,
    errors: errors
  };
}

module.exports = { validatePayload };
```

---

## üéØ Checklist de D√©ploiement

### Code & Configuration
- [ ] Frontend data-sender.js modifi√© (inputType + data wrapper)
- [ ] Scripts de validation cr√©√©s
- [ ] config.js avec les 3 types d'entr√©es

### Google Sheets
- [ ] Sheet "DictaMed_Users" avec prompts
- [ ] Sheets r√©sultats cr√©√©s pour chaque utilisateur
- [ ] Service account partag√© avec permissions Editor

### n8n Workflow
- [ ] Webhook /webhook/DictaMed cr√©√©
- [ ] N≈ìud 1: Webhook Trigger
- [ ] N≈ìud 2: Google Sheets Lookup
- [ ] N≈ìud 3: IF user found
- [ ] N≈ìud 4: Code JS context
- [ ] N≈ìud 5: Switch routing par inputType
- [ ] N≈ìud 5.1-5.3: Audio path (Whisper ‚Üí Agent)
- [ ] N≈ìud 5.4-5.5: Text path (Direct ‚Üí Agent)
- [ ] N≈ìud 5.6-5.8: Photo path (Vision ‚Üí Agent)
- [ ] N≈ìud 6: Code JS consolidation
- [ ] N≈ìud 7: Google Sheets Append
- [ ] N≈ìud 8: HTTP Response

### Tests
- [ ] Test payload audio complet
- [ ] Test payload texte complet
- [ ] Test payload photo complet
- [ ] V√©rifier Google Sheets avec 3 types
- [ ] Test erreur handling (API down, invalid data)
- [ ] Test performance (timeouts, rate limits)

### Monitoring
- [ ] Logs n8n configur√©s
- [ ] Alertes email/Slack configur√©es
- [ ] Dashboard monitoring cr√©√©

---

## üîó Ressources

| Document | Description |
|----------|------------|
| ARCHITECTURE_SIMPLIFIEE.md | Vue d'ensemble v1 |
| N8N_WORKFLOW_SETUP.md | Guide original (v1) |
| N8N_CONDITIONAL_WORKFLOW_V2.md | Ce document (v2) |
| PROCHAINES_ETAPES.md | √âtapes d√©ploiement |

---

## üìû Support & Troubleshooting

### Erreur: "inputType invalide"
**Cause:** Frontend n'envoie pas inputType ou valeur invalide
**Solution:** V√©rifier data-sender.js, ajouter validation

### Erreur: "Whisper API failed" (Audio path seulement)
**Cause:** Audio format invalide ou API down
**Solution:** V√©rifier format audio (webm, mp3), tester cl√© API

### Erreur: "Vision API failed" (Photo path seulement)
**Cause:** Image format invalide ou trop grosse
**Solution:** V√©rifier format (JPEG, PNG), redimensionner

### Erreur: "Agent structuration failed" (Tous les chemins)
**Cause:** Prompt invalide ou r√©ponse non-JSON
**Solution:** V√©rifier prompt dans Google Sheets, ajouter parser robuste

### Donn√©es manquantes dans Google Sheets
**Cause:** Colonnes non cr√©√©es ou AppendRow mal configur√©
**Solution:** V√©rifier liste des colonnes, comparer avec output du Code JS

---

## üìä Exemple R√©sultat Final (Google Sheets)

| timestamp | uid | email | inputType | sympt√¥mes | diagnostic | actions | tokens |
|-----------|-----|-------|-----------|-----------|-----------|---------|--------|
| 2025-01-15T10:30:00Z | abc123 | student@med.fr | audio | Douleurs thoraciques, dyspn√©e | Infarctus probable | ECG, Troponine | 542 |
| 2025-01-15T11:00:00Z | abc123 | student@med.fr | text | C√©phal√©es, photophobie | Migraine | Repos, Triptan | 387 |
| 2025-01-15T11:30:00Z | abc123 | student@med.fr | photo | Opacit√© apicale gauche | TB pulmonaire | PCR, ImageBMP | 621 |

---

**Version:** 2.0
**Derni√®re mise √† jour:** 2025-01-15
**Statut:** Architecture Multi-Entr√©es avec Agent OpenAI
